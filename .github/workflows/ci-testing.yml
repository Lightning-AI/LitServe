name: CI testing

on:
  push:
    branches: [main, "release/*"]
  pull_request:
    branches: [main, "release/*"]

env:
  UV_SYSTEM_PYTHON: 1

defaults:
  run:
    shell: bash

jobs:
  pytester:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.9", "3.10", "3.11"] # todo, "3.12"
        include:
          - { os: "macos-latest", python-version: "3.12" }
          - { os: "windows-latest", python-version: "3.11" }
          - { os: "ubuntu-22.04", python-version: "3.9", requires: "oldest" }

    timeout-minutes: 35
    env:
      TORCH_URL: "https://download.pytorch.org/whl/cpu/torch_stable.html"

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v5

      - name: Set up Python ${{ matrix.python-version }}
        uses: astral-sh/setup-uv@v5
        with:
          python-version: ${{ matrix.python-version }}
          enable-cache: true

      - name: Set min. dependencies
        if: matrix.requires == 'oldest'
        run: |
          uv pip install 'lightning-utilities[cli]'
          uv run python -m lightning_utilities.cli requirements set-oldest --req_files='["requirements.txt", "_requirements/test.txt"]'

      - name: Install package & dependencies
        run: |
          uv pip install -e '.[test]' -U -q --find-links $TORCH_URL
          uv pip list

      - name: Tests
        timeout-minutes: 15
        run: |
          uv run pytest --cov=litserve src/ tests/ -v -s --durations=100

      - name: Statistics
        run: |
          uv run coverage report
          uv run coverage xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage.xml
          flags: unittests
          env_vars: OS,PYTHON
          name: codecov-umbrella
          fail_ci_if_error: false

  tests-guardian:
    runs-on: ubuntu-latest
    needs: pytester
    if: always()
    steps:
      - run: echo "${{ needs.pytester.result }}"
      - name: failing...
        if: needs.pytester.result == 'failure'
        run: exit 1
      - name: cancelled or skipped...
        if: contains(fromJSON('["cancelled", "skipped"]'), needs.pytester.result)
        timeout-minutes: 1
        run: sleep 90
